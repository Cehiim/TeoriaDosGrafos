{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Informações gerais"
      ],
      "metadata": {
        "id": "nL7lcvob_Vsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tema\n",
        "* Aplicação de encoder para RAG (*Retrieval Augmented Generation*)"
      ],
      "metadata": {
        "id": "UU8Q8ZzuEOEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integrantes\n",
        "* Cesar Hideki Imai - 10402758\n",
        "* João Victor Dallapé Madeira - 10400725\n",
        "* David Varão Lima Bentes Pessoa - 1040264"
      ],
      "metadata": {
        "id": "yG-5rVdzEVkl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX9e_J1rfR8k"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Fd36vBfY_m"
      },
      "source": [
        "## Integração dos pacotes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_J43xnrFIo"
      },
      "source": [
        "O pacote `vectordb2` é usado para armazenar e recuperar textos usando técnicas de *chunking* (segmentação de texto), *embedding* (conversão de texto para vetores numéricos) e busca vetorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yy3H5b34UlKV",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "09eefc5d-1252-49ff-e3fb-8ab47b85a4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vectordb2 in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (4.44.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.13.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from vectordb2) (3.1.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.8.0.post1)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.17.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (10.4.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->vectordb2) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->vectordb2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->vectordb2) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.12.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install vectordb2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O pacote requests pode ser usado para recuperar o arquivo por meio de requisição em HTTP (esse pacote é opcional)."
      ],
      "metadata": {
        "id": "WZDIGMyXB04o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install requests"
      ],
      "metadata": {
        "id": "FucP-UzdB1B3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b12f32a4-4076-481e-8e0d-d93fc81d09fc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OtxcQzT2JAX"
      },
      "source": [
        "O pacote `networkx` é usado para a criação, manipulação e representação de grafos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "hVwSlpPSeJPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090c288f-c24b-4277-8cdc-72974a98e0ac",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install networkx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das bibliotecas"
      ],
      "metadata": {
        "id": "DjtCEtpOCxs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vectordb import Memory\n",
        "import requests\n",
        "import networkx\n",
        "import os # Será usado métodos para limpar o terminal para atualizar a interface em cada iteração do sistema\n",
        "import time # Será usado método de espera para atualizar a interface gradualmente"
      ],
      "metadata": {
        "id": "DA_HyrBKC6J0"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "jUL4VcKo2JAl"
      },
      "source": [
        "## Classe Grafo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Feb 13 13:59:10 2023\n",
        "\n",
        "@author: icalc\n",
        "\"\"\"\n",
        "class Grafo:\n",
        "    TAM_MAX_DEFAULT = 100 # qtde de vértices máxima default\n",
        "    # construtor da classe grafo\n",
        "    def __init__(self, n=TAM_MAX_DEFAULT):\n",
        "        self.n = n # número de vértices\n",
        "        self.m = 0 # número de arestas\n",
        "        # matriz de adjacência\n",
        "        self.adj = [[0 for i in range(n)] for j in range(n)]\n",
        "\n",
        "\t# Insere uma aresta no Grafo tal que\n",
        "\t# v é adjacente a w\n",
        "    def insereA(self, v, w):\n",
        "        if self.adj[v][w] == 0:\n",
        "            self.adj[v][w] = 1\n",
        "            self.m+=1 # atualiza qtd arestas\n",
        "\n",
        "# remove uma aresta v->w do Grafo\n",
        "    def removeA(self, v, w):\n",
        "        if(v == w):\n",
        "            return\n",
        "        # testa se temos a aresta\n",
        "        if self.adj[v][w] == 1:\n",
        "            self.adj[v][w] = 0\n",
        "            self.m -= 1  # atualiza qtd arestas\n",
        "\n",
        "\t# Apresenta o Grafo contendo\n",
        "\t# número de vértices, arestas\n",
        "\t# e a matriz de adjacência obtida\n",
        "    def show(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                if self.adj[i][w] == 1:\n",
        "                    print(f\"Adj[{i:2d},{w:2d}] = 1 \", end=\"\")\n",
        "                else:\n",
        "                    print(f\"Adj[{i:2d},{w:2d}] = 0 \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )\n",
        "\n",
        "\n",
        "\t# Apresenta o Grafo contendo\n",
        "\t# número de vértices, arestas\n",
        "\t# e a matriz de adjacência obtida\n",
        "    # Apresentando apenas os valores 0 ou 1\n",
        "    def showMin(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                if self.adj[i][w] == 1:\n",
        "                    print(\" 1 \", end=\"\")\n",
        "                else:\n",
        "                    print(\" 0 \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )\n",
        "\n",
        "    def leGrafo(self, path):\n",
        "        with open(path, 'r',encoding='utf-8') as arquivo:\n",
        "            n_palavras = int(arquivo.readline())\n",
        "\n",
        "            palavras = []\n",
        "            for i in range(n_palavras):\n",
        "                palavras.append(arquivo.readline().strip())\n",
        "        print(palavras)\n",
        "        print(n_palavras)"
      ],
      "metadata": {
        "id": "yAaYISkbfzOE"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classe GrafoND (Grafo não-direcionado)"
      ],
      "metadata": {
        "id": "g2sI3d7Qz7ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafo como uma matriz de adjacência não-direcionado\n",
        "class GrafoND(Grafo): # Ex 7\n",
        "    def __init__(self, n):\n",
        "        super().__init__(n)\n",
        "\n",
        "    def insereA(self, v, w):\n",
        "        if(v == w):\n",
        "            return\n",
        "        if self.adj[v][w] == 0:\n",
        "            self.adj[v][w] = 1\n",
        "            self.adj[w][v] = 1\n",
        "            self.m += 1  # atualiza qtd arestas\n",
        "\n",
        "# remove uma aresta v->w do Grafo\n",
        "    def removeA(self, v, w):\n",
        "        if(v == w):\n",
        "            return\n",
        "        # testa se temos a aresta\n",
        "        if self.adj[v][w] == 1:\n",
        "            self.adj[v][w] = 0\n",
        "            self.adj[w][v] = 0\n",
        "            self.m -= 1  # atualiza qtd arestas\n",
        "\n",
        "    def show(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(int(self.n)):\n",
        "            for w in range(self.n):\n",
        "                print(f\"Adj[{i:2d},{w:2d}] = {self.adj[i][w]:.2f} \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )\n",
        "\n",
        "    #Verifica se o grafo é completo Ex 10)\n",
        "    def ehCompleto(self):\n",
        "        if((self.n ** 2 - self.n)/ 2 == self.m):\n",
        "            return \"O grafo é completo\"\n",
        "        else:\n",
        "            return \"O grafo não é completo\"\n",
        "\n",
        "    def conexidade(self): # Ex 13\n",
        "        if(self.n > 1 and self.m == 0):\n",
        "            return \"O grafo não é conexo\"\n",
        "        passou = [0]\n",
        "        for i in range(self.n):\n",
        "            if(not i in passou):\n",
        "                return \"O grafo não é conexo\"\n",
        "            for j in range(self.n):\n",
        "                if(i != j and self.adj[i][j] != 0 and not j in passou):\n",
        "                    passou.append(j)\n",
        "                    #print(passou)\n",
        "        return \"O grafo é conexo\"\n",
        "\n",
        "    def removeV(self, vertice): # Ex 24\n",
        "        if(vertice >= self.n):\n",
        "            return False\n",
        "        for i in range(self.n-1):\n",
        "            if(i >= vertice): # Substitui as conexões do vértice a ser retirado e\n",
        "                              # os vértices posteriores a ele com as conexões do próximo vértice\n",
        "                self.adj[i] = self.adj[i+1]\n",
        "            self.removeA(i,vertice)\n",
        "            self.adj[i].pop(vertice) # Remove o vértice escolhido da linha da matriz\n",
        "        self.adj.pop() # Remove a última linha da matriz\n",
        "        self.n -= 1\n",
        "        return True"
      ],
      "metadata": {
        "id": "F1sOCb5P0ITt"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classe GrafoNDR (Grafo não-direcionado rotulado)"
      ],
      "metadata": {
        "id": "Nt727Vzj0Kos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafo como uma matriz de adjacência não-direcionado rotulado\n",
        "class GrafoNDR(GrafoND): # Ex 8\n",
        "# Não bota o init, vai bugar a classe\n",
        "\n",
        "    def insereA(self, v, w, p):\n",
        "        if(v == w):\n",
        "            return\n",
        "        if self.adj[v][w] == 0:\n",
        "            self.adj[v][w] = p\n",
        "            self.adj[w][v] = p\n",
        "            self.m += 1  # atualiza qtd arestas\n",
        "\n",
        "    def show(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                print(f\"Adj[{i:2d},{w:2d}] = {self.adj[i][w]:.2f} \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )\n",
        "\n",
        "\n",
        "\t# Apresenta o Grafo contendo\n",
        "\t# número de vértices, arestas\n",
        "\t# e a matriz de adjacência obtida\n",
        "    # Apresentando apenas os valores 0 ou 1\n",
        "    def showMin(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                print(f\" {self.adj[i][w]:.2f} \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )"
      ],
      "metadata": {
        "id": "lKyCUwc80StM"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classe Memory"
      ],
      "metadata": {
        "id": "XMuxrf07kEw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é utilizado a biblioteca VectorDB para criar uma memória virtual.\n",
        "\n",
        "```\n",
        "memoria = Memory(chunking_strategy={\"mode\": \"sliding_window\", \"window_size\": 1, \"overlap\": 0})\n",
        "```\n",
        "\n",
        "- `chunking_strategy`: Define a estratégia de fragmentação dos dados. No modo \"sliding_window\", os dados são divididos em *chunks* (pedaços de texto) de tamanho fixo.\n",
        "\n",
        "- `window_size`: Define a quantidade de palavras que um *chunk* representa. Neste caso, cada *chunk* representa uma palavra.\n",
        "\n",
        "- `overlap`: Define quantos elementos de sobreposição existirão entre os *chunks* adjacentes. Neste caso, não haverá sobreposição já que as palavras usadas não formam frases, logo são independentes uma das outras."
      ],
      "metadata": {
        "id": "a6uWsA4dkZwE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4oq-cagY8g"
      },
      "source": [
        "# Métodos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8LIYV32JAo"
      },
      "source": [
        "## 1. Ler dados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aquisição dos dados"
      ],
      "metadata": {
        "id": "cxpnmvFW3RZ_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPQ65cuK2JAo"
      },
      "source": [
        "Os dados do documento são importados e guardados na variável `dados`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "-7q8lJ7B2JAq"
      },
      "outputs": [],
      "source": [
        "def leArquivoHTTP():\n",
        "  arquivo = requests.get('https://raw.githubusercontent.com/Cehiim/TeoriaDosGrafos/refs/heads/main/Projeto/palavras.txt').text\n",
        "\n",
        "  palavras = arquivo.split()\n",
        "  n_palavras = int(palavras.pop(0))\n",
        "  dados = {\n",
        "      \"n_palavras\": n_palavras,\n",
        "      \"palavras\": palavras\n",
        "  }\n",
        "\n",
        "  return dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "collapsed": true,
        "id": "qbPmOab62JAr"
      },
      "outputs": [],
      "source": [
        "def leArquivo(origem):\n",
        "  with open(origem, 'r', encoding='utf-8') as arquivo:\n",
        "    n_palavras = int(arquivo.readline())\n",
        "\n",
        "    palavras = [\"\"] * n_palavras\n",
        "    for i in range(n_palavras):\n",
        "      palavras[i] = arquivo.readline().strip()\n",
        "\n",
        "  dados = {\n",
        "      \"n_palavras\": n_palavras,\n",
        "      \"palavras\": palavras\n",
        "  }\n",
        "\n",
        "  return dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WJkcynqo2JAr",
        "outputId": "f05acb18-affd-4084-ee1c-8ffb30ce71f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_palavras': 50, 'palavras': ['Ecossistema', 'Sustentabilidade', 'Biodiversidade', 'Reciclagem', 'Conservação', 'Poluição', 'Desmatamento', 'Reflorestamento', 'Erosão', 'Compostagem', 'Biodegradável', 'Emissões', 'Pegada', 'Recursos', 'Preservação', 'Ecologia', 'Habitat', 'Fauna', 'Flora', 'Agroecologia', 'Bioma', 'Ciclo', 'Desenvolvimento', 'Economia', 'Efluentes', 'Gestão', 'Impacto', 'Mata', 'Amazônia', 'Cerrado', 'Pantanal', 'Biotecnologia', 'Agrofloresta', 'Agricultura', 'Aquicultura', 'Biocombustível', 'Solar', 'Eólica', 'Hidrelétrica', 'Resíduos', 'Saneamento', 'Tratamento', 'Uso', 'Zona', 'Proteção', 'Ambiental', 'Clima', 'Solo', 'Água', 'Floresta']}\n"
          ]
        }
      ],
      "source": [
        "#d = leArquivoHTTP()\n",
        "d = leArquivo(\"./Projeto/palavras.txt\")\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding"
      ],
      "metadata": {
        "id": "u6KpszTx9wbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada palavra é convertida para um vetor numérico e guardada na memória."
      ],
      "metadata": {
        "id": "0kRX7-7r-BjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding(memoria, palavras, n_palavras):\n",
        "  for i in range(n_palavras):\n",
        "    memoria.save(palavras[i])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4PR45aSh97GE"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Busca vetorial"
      ],
      "metadata": {
        "id": "XCD1aKeV-eSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quanto menor é a distância, maior é a proximidade semântica."
      ],
      "metadata": {
        "id": "RQUG4Hf4-oNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscaVetorial(memoria, palavra):\n",
        "  busca = memoria.search(palavra, top_n=6)\n",
        "  return busca"
      ],
      "metadata": {
        "id": "iFWuMWvQpgFW"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A palavra mais próxima armazenada na memória é ela mesma, portanto para encontrar as outras cinco palavras mais próximas foi recuperado as palavras de índice 1 até 6."
      ],
      "metadata": {
        "id": "LKs0zciNBHL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = Memory(chunking_strategy={\"mode\": \"sliding_window\", \"window_size\": 1, \"overlap\": 0})\n",
        "n = d[\"n_palavras\"]\n",
        "p = d[\"palavras\"]\n",
        "\n",
        "embedding(m, p, n)\n",
        "\n",
        "b = buscaVetorial(m, \"Biodiversidade\")\n",
        "print(b)\n",
        "print(f\"\\n\\nBusca: Biodiversidade\\n\")\n",
        "for i in range(1,6):\n",
        "  palavra = b[i]['chunk']\n",
        "  distancia = b[i]['distance']\n",
        "  print(f\"Palavra: {palavra}\\nDistância: {distancia:.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBe9Eq_I-ozC",
        "outputId": "2b822dc9-03c5-4703-8f5f-728e0172fe3b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiliazing embeddings:  normal\n",
            "OK.\n",
            "[{'chunk': 'Biodiversidade', 'metadata': {}, 'distance': 0.0}, {'chunk': 'Sustentabilidade', 'metadata': {}, 'distance': 0.44970125}, {'chunk': 'Agroecologia', 'metadata': {}, 'distance': 0.492421}, {'chunk': 'Biotecnologia', 'metadata': {}, 'distance': 0.49487936}, {'chunk': 'Biodegradável', 'metadata': {}, 'distance': 0.5287854}, {'chunk': 'Bioma', 'metadata': {}, 'distance': 0.5513243}]\n",
            "\n",
            "\n",
            "Busca: Biodiversidade\n",
            "\n",
            "Palavra: Sustentabilidade\n",
            "Distância: 0.45\n",
            "\n",
            "Palavra: Agroecologia\n",
            "Distância: 0.49\n",
            "\n",
            "Palavra: Biotecnologia\n",
            "Distância: 0.49\n",
            "\n",
            "Palavra: Biodegradável\n",
            "Distância: 0.53\n",
            "\n",
            "Palavra: Bioma\n",
            "Distância: 0.55\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integração no grafo"
      ],
      "metadata": {
        "id": "oQpdmDli23KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def integraGrafo(memoria, palavras, n_palavras):\n",
        "  grafo = GrafoNDR(n_palavras)\n",
        "  for i in range(n_palavras):\n",
        "    busca = buscaVetorial(memoria, palavras[i])\n",
        "    for j in range(1,6):\n",
        "      palavra = busca[j]['chunk']\n",
        "      distancia = busca[j]['distance']"
      ],
      "metadata": {
        "id": "NuGHaDAJ25c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsUUPVLa2JAs"
      },
      "source": [
        "## 2. Gravar dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "S8aX3NJd2JAs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcUaBUFE2JAs"
      },
      "source": [
        "## 3. Inserir vértice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "rEUyOKTo2JAt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8PvH4ed2JAt"
      },
      "source": [
        "## 4. Inserir aresta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "6u2WV2hb2JAt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMVke0Al2JAt"
      },
      "source": [
        "## 5. Remover vértice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "CqO6N1PP2JAu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvUaJjZS2JAu"
      },
      "source": [
        "## 6. Remover aresta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "hmD-cjiW2JAu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8SKdKg2JAv"
      },
      "source": [
        "## 7. Mostrar conteúdo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "tlbI-jgd2JA1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS8x6Fjd2JA2"
      },
      "source": [
        "## 8. Mostrar grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "J6uG3Bl12JA2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs6GqASM2JA2"
      },
      "source": [
        "## 9. Apresentar conexidade do grafo e o reduzido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "sUTjaER52JA2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YNbDvEe2JA3"
      },
      "source": [
        "# Menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "AdLQfMUkWbyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cefdded-1288-43c0-e3b9-7776ad7682ca",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiliazing embeddings:  normal\n",
            "OK.\n",
            "\n",
            "Menu:\n",
            "    1) Ler dados do arquivo em python\n",
            "    2) Gravar dados no arquivo grafo.txt\n",
            "    3) Inserir vértice\n",
            "    4) Inserir aresta\n",
            "    5) Remove vértice\n",
            "    6) Remove aresta\n",
            "    7) Mostrar conteúdo do arquivo\n",
            "    8) Mostrar grafo\n",
            "    9) Apresentar a conexidade do grafo e o reduzido\n",
            "    10) Encerrar a aplicação\n",
            "\n",
            "1\n",
            "Grafo lido com sucesso!\n",
            "\n",
            "Menu:\n",
            "    1) Ler dados do arquivo em python\n",
            "    2) Gravar dados no arquivo grafo.txt\n",
            "    3) Inserir vértice\n",
            "    4) Inserir aresta\n",
            "    5) Remove vértice\n",
            "    6) Remove aresta\n",
            "    7) Mostrar conteúdo do arquivo\n",
            "    8) Mostrar grafo\n",
            "    9) Apresentar a conexidade do grafo e o reduzido\n",
            "    10) Encerrar a aplicação\n",
            "\n",
            "10\n",
            "Encerrando programa...\n"
          ]
        }
      ],
      "source": [
        "memoria = Memory(chunking_strategy={\"mode\": \"sliding_window\", \"window_size\": 1, \"overlap\": 0})\n",
        "fim = False\n",
        "\n",
        "while(fim == False):\n",
        "    print(\n",
        "'''\n",
        "Menu:\n",
        "    1) Ler dados do arquivo em python\n",
        "    2) Gravar dados no arquivo grafo.txt\n",
        "    3) Inserir vértice\n",
        "    4) Inserir aresta\n",
        "    5) Remove vértice\n",
        "    6) Remove aresta\n",
        "    7) Mostrar conteúdo do arquivo\n",
        "    8) Mostrar grafo\n",
        "    9) Apresentar a conexidade do grafo e o reduzido\n",
        "    10) Encerrar a aplicação\n",
        "''')\n",
        "    choice = int(input())\n",
        "    if choice == 1: # Lê grafo\n",
        "        dados = leArquivoHTTP()\n",
        "        #dados = leArquivo(\"palavras.txt\")\n",
        "        embedding(memoria, dados[\"palavras\"], dados[\"n_palavras\"])\n",
        "        print(\"Grafo lido com sucesso!\")\n",
        "\n",
        "    elif choice == 2: # Grava dados no arquivo .txt\n",
        "        print(\"Dados salvos com sucesso!\")\n",
        "\n",
        "    elif choice == 3: # Insere vértice\n",
        "        print(\"Vértice inserido com sucesso!\")\n",
        "\n",
        "    elif choice == 4: # Insere aresta\n",
        "        print(\"Arestas inseridas com sucesso!\")\n",
        "\n",
        "    elif choice == 5: # Remove vértice\n",
        "        print(\"Vértice removido com sucesso!\")\n",
        "\n",
        "    elif choice == 6: # Remove varesta\n",
        "        print(\"Aresta removida com sucesso!\")\n",
        "\n",
        "    elif choice == 7: # Imprime arquivo\n",
        "        print(\"oi\")\n",
        "\n",
        "    elif choice == 8: # Exibe grafo\n",
        "        print(\"oi\")\n",
        "\n",
        "    elif choice == 9: # Apresenta a conexidade do grafo e grafo reduzido\n",
        "        print(\"oi\")\n",
        "\n",
        "    elif choice == 10: # Encerra\n",
        "        fim = True\n",
        "        print(\"Encerrando programa...\")\n",
        "\n",
        "    else:\n",
        "        print(\"Opção inválida.\")\n",
        "\n",
        "    time.sleep(4) # Volta para o menu após 4 segundos\n",
        "\n",
        "    if os.name == 'nt': # Limpa o terminal\n",
        "        os.system('cls') # Caso o OS seja Windows\n",
        "    else:\n",
        "        os.system('clear') # Caso o OS seja Linux ou MacOS"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nL7lcvob_Vsv",
        "f4Fd36vBfY_m",
        "jUL4VcKo2JAl",
        "g2sI3d7Qz7ck",
        "Nt727Vzj0Kos",
        "XMuxrf07kEw_",
        "rsUUPVLa2JAs",
        "rcUaBUFE2JAs",
        "-8PvH4ed2JAt",
        "nMVke0Al2JAt",
        "cvUaJjZS2JAu",
        "4f8SKdKg2JAv",
        "kS8x6Fjd2JA2",
        "hs6GqASM2JA2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}