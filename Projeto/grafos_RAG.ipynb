{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cehiim/TeoriaDosGrafos/blob/main/Projeto/grafos_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX9e_J1rfR8k"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Fd36vBfY_m"
      },
      "source": [
        "## Integração dos pacotes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_J43xnrFIo"
      },
      "source": [
        "O pacote `vectordb2` é usado para armazenar e recuperar textos usando técnicas de *chunking* (segmentação de texto), *embedding* (conversão de texto para vetores numéricos) e busca vetorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yy3H5b34UlKV",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "73141ded-5624-40e6-fb62-909f609c22fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vectordb2 in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (4.44.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.13.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from vectordb2) (3.1.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.8.0.post1)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.17.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (10.4.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->vectordb2) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->vectordb2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->vectordb2) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.12.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->vectordb2) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install vectordb2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZDIGMyXB04o"
      },
      "source": [
        "O pacote requests pode ser usado para recuperar o arquivo por meio de requisição em HTTP (esse pacote é opcional)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FucP-UzdB1B3",
        "outputId": "f55193a6-e5c7-4336-c136-d768c6b7cb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "%pip install requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OtxcQzT2JAX"
      },
      "source": [
        "O pacote `networkx` é usado para a criação, manipulação e representação de grafos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hVwSlpPSeJPm",
        "outputId": "15e3a316-8dfe-4fcb-ec17-12d543c64cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install networkx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjtCEtpOCxs2"
      },
      "source": [
        "Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DA_HyrBKC6J0"
      },
      "outputs": [],
      "source": [
        "from vectordb import Memory\n",
        "import requests\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt # Será usado para apresentação visual do grafo\n",
        "import os # Será usado métodos para limpar o terminal para atualizar a interface em cada iteração do sistema\n",
        "import time # Será usado método de espera para atualizar a interface gradualmente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUL4VcKo2JAl",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Classe Grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "yAaYISkbfzOE"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Feb 13 13:59:10 2023\n",
        "\n",
        "@author: icalc\n",
        "\"\"\"\n",
        "class Grafo:\n",
        "    TAM_MAX_DEFAULT = 100 # qtde de vértices máxima default\n",
        "    # construtor da classe grafo\n",
        "    def __init__(self, n=TAM_MAX_DEFAULT):\n",
        "        self.n = n # número de vértices\n",
        "        self.m = 0 # número de arestas\n",
        "        # matriz de adjacência\n",
        "        self.adj = [[0 for i in range(n)] for j in range(n)]\n",
        "\n",
        "\t# Insere uma aresta no Grafo tal que\n",
        "\t# v é adjacente a w\n",
        "    def insereA(self, v, w):\n",
        "        if self.adj[v][w] == 0:\n",
        "            self.adj[v][w] = 1\n",
        "            self.m+=1 # atualiza qtd arestas\n",
        "\n",
        "# remove uma aresta v->w do Grafo\n",
        "    def removeA(self, v, w):\n",
        "        if(v == w):\n",
        "            return\n",
        "        # testa se temos a aresta\n",
        "        if self.adj[v][w] == 1:\n",
        "            self.adj[v][w] = 0\n",
        "            self.m -= 1  # atualiza qtd arestas\n",
        "\n",
        "\t# Apresenta o Grafo contendo\n",
        "\t# número de vértices, arestas\n",
        "\t# e a matriz de adjacência obtida\n",
        "    def show(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                if self.adj[i][w] == 1:\n",
        "                    print(f\"Adj[{i:2d},{w:2d}] = 1 \", end=\"\")\n",
        "                else:\n",
        "                    print(f\"Adj[{i:2d},{w:2d}] = 0 \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )\n",
        "\n",
        "\n",
        "\t# Apresenta o Grafo contendo\n",
        "\t# número de vértices, arestas\n",
        "\t# e a matriz de adjacência obtida\n",
        "    # Apresentando apenas os valores 0 ou 1\n",
        "    def showMin(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                if self.adj[i][w] == 1:\n",
        "                    print(\" 1 \", end=\"\")\n",
        "                else:\n",
        "                    print(\" 0 \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )\n",
        "\n",
        "    def plota_grafo(self):\n",
        "        # Criar um grafo dirigido usando a matriz de adjacência\n",
        "        G = nx.DiGraph()  # Grafo dirigido\n",
        "\n",
        "        # Adicionar vértices e arestas\n",
        "        for i in range(self.n):\n",
        "            for j in range(self.n):\n",
        "                if self.adj[i][j] == 1:\n",
        "                    G.add_edge(i, j)\n",
        "\n",
        "        # Plotar o grafo\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        pos = nx.spring_layout(G)  # Layout para a posição dos nós\n",
        "        nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500, font_size=10, font_color='black', arrowstyle='-|>', arrowsize=20)\n",
        "        plt.title(f\"Grafo com {self.n} vértices e {self.m} arestas\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2sI3d7Qz7ck"
      },
      "source": [
        "## Classe GrafoR (Grafo direcionado rotulado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "F1sOCb5P0ITt"
      },
      "outputs": [],
      "source": [
        "# Grafo como uma matriz de adjacência rotulado\n",
        "class GrafoR(Grafo): # Ex 16\n",
        "# Não bota o init, vai bugar a classe\n",
        "\n",
        "    def insereA(self, v, w, p):\n",
        "        if self.adj[v][w] == 0:\n",
        "            self.adj[v][w] = p\n",
        "            self.m += 1  # atualiza qtd arestas\n",
        "\n",
        "    def show(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                print(f\"Adj[{i:2d},{w:2d}] = {self.adj[i][w]:.2f} \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )\n",
        "\n",
        "\n",
        "\t# Apresenta o Grafo contendo\n",
        "\t# número de vértices, arestas\n",
        "\t# e a matriz de adjacência obtida\n",
        "    # Apresentando apenas os valores 0 ou 1\n",
        "    def showMin(self):\n",
        "        print(f\"\\n n: {self.n:2d} \", end=\"\")\n",
        "        print(f\"m: {self.m:2d}\\n\")\n",
        "        for i in range(self.n):\n",
        "            for w in range(self.n):\n",
        "                print(f\" {self.adj[i][w]:.2f} \", end=\"\")\n",
        "            print(\"\\n\")\n",
        "        print(\"\\nfim da impressao do grafo.\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMuxrf07kEw_"
      },
      "source": [
        "## Classe Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6uWsA4dkZwE"
      },
      "source": [
        "Aqui é utilizado a biblioteca VectorDB para criar uma memória virtual.\n",
        "\n",
        "```\n",
        "memoria = Memory(chunking_strategy={\"mode\": \"sliding_window\", \"window_size\": 1, \"overlap\": 0})\n",
        "```\n",
        "\n",
        "- `chunking_strategy`: Define a estratégia de fragmentação dos dados. No modo \"sliding_window\", os dados são divididos em *chunks* (pedaços de texto) de tamanho fixo.\n",
        "\n",
        "- `window_size`: Define a quantidade de palavras que um *chunk* representa. Neste caso, cada *chunk* representa uma palavra.\n",
        "\n",
        "- `overlap`: Define quantos elementos de sobreposição existirão entre os *chunks* adjacentes. Neste caso, não haverá sobreposição já que as palavras usadas não formam frases, logo são independentes uma das outras."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INIT"
      ],
      "metadata": {
        "id": "xvaddfZSJlrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "    def __init__(\n",
        "        self,\n",
        "        memory_file: str = None,\n",
        "        chunking_strategy: dict = None,\n",
        "        embeddings: Union[BaseEmbedder, str] = \"normal\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the Memory class.\n",
        "\n",
        "        :param memory_file: a string containing the path to the memory file. (default: None)\n",
        "        :param chunking_strategy: a dictionary containing the chunking mode (default: {\"mode\": \"sliding_window\"}).\n",
        "        :param embedding_model: a string containing the name of the pre-trained model to be used for embeddings (default: \"sentence-transformers/all-MiniLM-L6-v2\").\n",
        "        \"\"\"\n",
        "        self.memory_file = memory_file\n",
        "\n",
        "        if memory_file is None:\n",
        "            self.memory = []\n",
        "            self.metadata_memory = []\n",
        "        else:\n",
        "            load = Storage(memory_file).load_from_disk()       \n",
        "            self.memory = [] if len(load) != 1 else load[0][\"memory\"]\n",
        "            self.metadata_memory = [] if len(load) != 1 else load[0][\"metadata\"]\n",
        "\n",
        "        if chunking_strategy is None:\n",
        "            chunking_strategy = {\"mode\": \"sliding_window\"}\n",
        "        self.chunker = Chunker(chunking_strategy)\n",
        "\n",
        "        self.metadata_index_counter = 0\n",
        "        self.text_index_counter = 0\n",
        "\n",
        "        if isinstance(embeddings, str):\n",
        "            self.embedder = Embedder(embeddings)\n",
        "        elif isinstance(embeddings, BaseEmbedder):\n",
        "            self.embedder = embeddings\n",
        "        else:\n",
        "            raise TypeError(\"Embeddings must be an Embedder instance or string\")\n",
        "\n",
        "        self.vector_search = VectorSearch()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HGyXFhYFJHHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVE"
      ],
      "metadata": {
        "id": "qaQx_0LIJ6Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "    def save(\n",
        "        self,\n",
        "        texts,\n",
        "        metadata: Union[List, List[dict], None] = None,\n",
        "        memory_file: str = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Saves the given texts and metadata to memory.\n",
        "\n",
        "        :param texts: a string or a list of strings containing the texts to be saved.\n",
        "        :param metadata: a dictionary or a list of dictionaries containing the metadata associated with the texts.\n",
        "        :param memory_file: a string containing the path to the memory file. (default: None)\n",
        "        \"\"\"\n",
        "\n",
        "        if not isinstance(texts, list):\n",
        "            texts = [texts]\n",
        "\n",
        "        if metadata is None:\n",
        "            metadata = []\n",
        "        elif not isinstance(metadata, list):\n",
        "            metadata = [metadata]\n",
        "\n",
        "        # Extend metadata to be the same length as texts, if it's shorter.\n",
        "        metadata += [{}] * (len(texts) - len(metadata))\n",
        "\n",
        "        for meta in metadata:\n",
        "            self.metadata_memory.append(meta)\n",
        "\n",
        "        meta_index_start = (\n",
        "            self.metadata_index_counter\n",
        "        )  # Starting index for this save operation\n",
        "        self.metadata_index_counter += len(\n",
        "            metadata\n",
        "        )  # Update the counter for future save operations\n",
        "\n",
        "        if memory_file is None:\n",
        "            memory_file = self.memory_file\n",
        "\n",
        "        text_chunks = [self.chunker(text) for text in texts]\n",
        "        chunks_size = [len(chunks) for chunks in text_chunks]\n",
        "\n",
        "        flatten_chunks = list(itertools.chain.from_iterable(text_chunks))\n",
        "\n",
        "        embeddings = self.embedder.embed_text(flatten_chunks)\n",
        "\n",
        "        text_index_start = (\n",
        "            self.text_index_counter\n",
        "        )  # Starting index for this save operation\n",
        "        self.text_index_counter += len(texts)\n",
        "\n",
        "        # accumulated size is end_index of each chunk\n",
        "        for size, end_index, chunks, meta_index, text_index in zip(\n",
        "            chunks_size,\n",
        "            itertools.accumulate(chunks_size),\n",
        "            text_chunks,\n",
        "            range(meta_index_start, self.metadata_index_counter),\n",
        "            range(text_index_start, self.text_index_counter),\n",
        "        ):\n",
        "            start_index = end_index - size\n",
        "            chunks_embedding = embeddings[start_index:end_index]\n",
        "\n",
        "            for chunk, embedding in zip(chunks, chunks_embedding):\n",
        "                entry = {\n",
        "                    \"chunk\": chunk,\n",
        "                    \"embedding\": embedding,\n",
        "                    \"metadata_index\": meta_index,\n",
        "                    \"text_index\": text_index,\n",
        "                }\n",
        "                self.memory.append(entry)\n",
        "\n",
        "        if memory_file is not None:\n",
        "            Storage(self.memory_file).save_to_disk([{\"memory\": self.memory, \"metadata\" :self.metadata_memory}])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "czHNUzrrKVMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SEARCH"
      ],
      "metadata": {
        "id": "i5xPO7sqKCUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "    def search(\n",
        "        self, query: str, top_n: int = 5, unique: bool = False, batch_results: str = \"flatten\"\n",
        "    ) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Searches for the most similar chunks to the given query in memory.\n",
        "\n",
        "        :param query: a string containing the query text.\n",
        "        :param top_n: the number of most similar chunks to return. (default: 5)\n",
        "        :param unique: chunks are filtered out to unique texts (default: False)\n",
        "        :param batch_results: if input is list of queries, results can use \"flatten\" or \"diverse\" algorithm\n",
        "        :return: a list of dictionaries containing the top_n most similar chunks and their associated metadata.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(query, list):\n",
        "            query_embedding = self.embedder.embed_text(query)\n",
        "        else:\n",
        "            query_embedding = self.embedder.embed_text([query])[0]\n",
        "\n",
        "        \n",
        "        embeddings = [entry[\"embedding\"] for entry in self.memory]\n",
        "\n",
        "        indices = self.vector_search.search_vectors(query_embedding, embeddings, top_n, batch_results)\n",
        "        if unique:\n",
        "            unique_indices = []\n",
        "            seen_text_indices = set()  # Change the variable name\n",
        "            for i in indices:\n",
        "                text_index = self.memory[i[0]][\n",
        "                    \"text_index\"\n",
        "                ]  # Use text_index instead of metadata_index\n",
        "                if (\n",
        "                    text_index not in seen_text_indices\n",
        "                ):  # Use seen_text_indices instead of seen_meta_indices\n",
        "                    unique_indices.append(i)\n",
        "                    seen_text_indices.add(\n",
        "                        text_index\n",
        "                    )  # Use seen_text_indices instead of seen_meta_indices\n",
        "            indices = unique_indices\n",
        "\n",
        "        results = [\n",
        "            {\n",
        "                \"chunk\": self.memory[i[0]][\"chunk\"],\n",
        "                \"metadata\": self.metadata_memory[self.memory[i[0]][\"metadata_index\"]],\n",
        "                \"distance\": i[1],\n",
        "            }\n",
        "            for i in indices\n",
        "        ]\n",
        "\n",
        "        return results\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GdwM9rAdKjam"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4oq-cagY8g"
      },
      "source": [
        "# Métodos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8LIYV32JAo"
      },
      "source": [
        "## 1. Ler dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxpnmvFW3RZ_"
      },
      "source": [
        "### Aquisição dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPQ65cuK2JAo"
      },
      "source": [
        "Os dados do documento são importados e guardados na variável `dados`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "-7q8lJ7B2JAq"
      },
      "outputs": [],
      "source": [
        "def leArquivoHTTP():\n",
        "  arquivo = requests.get('https://raw.githubusercontent.com/Cehiim/TeoriaDosGrafos/refs/heads/main/Projeto/palavras.txt').text\n",
        "\n",
        "  lista = arquivo.split()\n",
        "  n_palavras = int(lista.pop(0))\n",
        "  vertices = []\n",
        "  for i in range(n_palavras):\n",
        "    vertice = {\n",
        "        \"palavra\": lista[i],\n",
        "        \"indice\": i,\n",
        "        \"proximos\": []\n",
        "    }\n",
        "    vertices.append(vertice)\n",
        "\n",
        "  dados = [n_palavras]\n",
        "  dados.append(vertices)\n",
        "\n",
        "  return dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "collapsed": true,
        "id": "qbPmOab62JAr"
      },
      "outputs": [],
      "source": [
        "def leArquivo(origem):\n",
        "  with open(origem, 'r', encoding='utf-8') as arquivo:\n",
        "    n_palavras = int(arquivo.readline())\n",
        "\n",
        "    vertices = []\n",
        "    for i in range(n_palavras):\n",
        "      vertice = {\n",
        "          \"palavra\": arquivo.readline().strip(),\n",
        "          \"indice\": i,\n",
        "          \"proximos\": []\n",
        "      }\n",
        "      vertices.append(vertice)\n",
        "\n",
        "  dados = [n_palavras]\n",
        "  dados.append(vertices)\n",
        "\n",
        "  return dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WJkcynqo2JAr",
        "outputId": "71184451-f563-4d79-d840-8750469c2b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50, [{'palavra': 'Ecossistema', 'indice': 0, 'proximos': []}, {'palavra': 'Sustentabilidade', 'indice': 1, 'proximos': []}, {'palavra': 'Biodiversidade', 'indice': 2, 'proximos': []}, {'palavra': 'Reciclagem', 'indice': 3, 'proximos': []}, {'palavra': 'Conservação', 'indice': 4, 'proximos': []}, {'palavra': 'Poluição', 'indice': 5, 'proximos': []}, {'palavra': 'Desmatamento', 'indice': 6, 'proximos': []}, {'palavra': 'Reflorestamento', 'indice': 7, 'proximos': []}, {'palavra': 'Erosão', 'indice': 8, 'proximos': []}, {'palavra': 'Compostagem', 'indice': 9, 'proximos': []}, {'palavra': 'Biodegradável', 'indice': 10, 'proximos': []}, {'palavra': 'Emissões', 'indice': 11, 'proximos': []}, {'palavra': 'Pegada', 'indice': 12, 'proximos': []}, {'palavra': 'Recursos', 'indice': 13, 'proximos': []}, {'palavra': 'Preservação', 'indice': 14, 'proximos': []}, {'palavra': 'Ecologia', 'indice': 15, 'proximos': []}, {'palavra': 'Habitat', 'indice': 16, 'proximos': []}, {'palavra': 'Fauna', 'indice': 17, 'proximos': []}, {'palavra': 'Flora', 'indice': 18, 'proximos': []}, {'palavra': 'Agroecologia', 'indice': 19, 'proximos': []}, {'palavra': 'Bioma', 'indice': 20, 'proximos': []}, {'palavra': 'Ciclo', 'indice': 21, 'proximos': []}, {'palavra': 'Desenvolvimento', 'indice': 22, 'proximos': []}, {'palavra': 'Economia', 'indice': 23, 'proximos': []}, {'palavra': 'Efluentes', 'indice': 24, 'proximos': []}, {'palavra': 'Gestão', 'indice': 25, 'proximos': []}, {'palavra': 'Impacto', 'indice': 26, 'proximos': []}, {'palavra': 'Mata', 'indice': 27, 'proximos': []}, {'palavra': 'Amazônia', 'indice': 28, 'proximos': []}, {'palavra': 'Cerrado', 'indice': 29, 'proximos': []}, {'palavra': 'Pantanal', 'indice': 30, 'proximos': []}, {'palavra': 'Biotecnologia', 'indice': 31, 'proximos': []}, {'palavra': 'Agrofloresta', 'indice': 32, 'proximos': []}, {'palavra': 'Agricultura', 'indice': 33, 'proximos': []}, {'palavra': 'Aquicultura', 'indice': 34, 'proximos': []}, {'palavra': 'Biocombustível', 'indice': 35, 'proximos': []}, {'palavra': 'Solar', 'indice': 36, 'proximos': []}, {'palavra': 'Eólica', 'indice': 37, 'proximos': []}, {'palavra': 'Hidrelétrica', 'indice': 38, 'proximos': []}, {'palavra': 'Resíduos', 'indice': 39, 'proximos': []}, {'palavra': 'Saneamento', 'indice': 40, 'proximos': []}, {'palavra': 'Tratamento', 'indice': 41, 'proximos': []}, {'palavra': 'Uso', 'indice': 42, 'proximos': []}, {'palavra': 'Zona', 'indice': 43, 'proximos': []}, {'palavra': 'Proteção', 'indice': 44, 'proximos': []}, {'palavra': 'Ambiental', 'indice': 45, 'proximos': []}, {'palavra': 'Clima', 'indice': 46, 'proximos': []}, {'palavra': 'Solo', 'indice': 47, 'proximos': []}, {'palavra': 'Água', 'indice': 48, 'proximos': []}, {'palavra': 'Floresta', 'indice': 49, 'proximos': []}]]\n"
          ]
        }
      ],
      "source": [
        "d = leArquivoHTTP()\n",
        "#d = leArquivo(\"./Projeto/palavras.txt\")\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6KpszTx9wbx"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kRX7-7r-BjR"
      },
      "source": [
        "Cada palavra é convertida para um vetor numérico e guardada na memória."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "collapsed": true,
        "id": "4PR45aSh97GE"
      },
      "outputs": [],
      "source": [
        "def embedding(memoria, vertices, n_palavras):\n",
        "  for i in range(n_palavras):\n",
        "    memoria.save(vertices[i][\"palavra\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCD1aKeV-eSW"
      },
      "source": [
        "### Busca vetorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQUG4Hf4-oNM"
      },
      "source": [
        "Quanto menor é a distância, maior é a proximidade semântica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "iFWuMWvQpgFW"
      },
      "outputs": [],
      "source": [
        "def buscaVetorial(memoria, palavra):\n",
        "  busca = memoria.search(palavra, top_n=6)\n",
        "  return busca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKs0zciNBHL_"
      },
      "source": [
        "A palavra mais próxima armazenada na memória é ela mesma, portanto para encontrar as outras cinco palavras mais próximas foi recuperado as palavras de índice 1 até 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBe9Eq_I-ozC",
        "outputId": "ebb1bac1-4db4-4e32-f3a9-8ed40c5ebfcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiliazing embeddings:  normal\n",
            "OK.\n",
            "[{'chunk': 'Biodiversidade', 'metadata': {}, 'distance': 0.0}, {'chunk': 'Sustentabilidade', 'metadata': {}, 'distance': 0.44970125}, {'chunk': 'Agroecologia', 'metadata': {}, 'distance': 0.492421}, {'chunk': 'Biotecnologia', 'metadata': {}, 'distance': 0.49487936}, {'chunk': 'Biodegradável', 'metadata': {}, 'distance': 0.5287854}, {'chunk': 'Bioma', 'metadata': {}, 'distance': 0.5513243}]\n",
            "\n",
            "\n",
            "Busca: Biodiversidade\n",
            "\n",
            "Palavra: Sustentabilidade\n",
            "Distância: 0.45\n",
            "\n",
            "Palavra: Agroecologia\n",
            "Distância: 0.49\n",
            "\n",
            "Palavra: Biotecnologia\n",
            "Distância: 0.49\n",
            "\n",
            "Palavra: Biodegradável\n",
            "Distância: 0.53\n",
            "\n",
            "Palavra: Bioma\n",
            "Distância: 0.55\n",
            "\n"
          ]
        }
      ],
      "source": [
        "m = Memory(chunking_strategy={\"mode\": \"sliding_window\", \"window_size\": 1, \"overlap\": 0})\n",
        "n = d[0]\n",
        "vs = d[1]\n",
        "\n",
        "embedding(m, vs, n)\n",
        "\n",
        "b = buscaVetorial(m, \"Biodiversidade\")\n",
        "print(b)\n",
        "print(f\"\\n\\nBusca: Biodiversidade\\n\")\n",
        "for i in range(1,6):\n",
        "  palavra = b[i]['chunk']\n",
        "  distancia = b[i]['distance']\n",
        "  print(f\"Palavra: {palavra}\\nDistância: {distancia:.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQpdmDli23KZ"
      },
      "source": [
        "### Integração no grafo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buscaIndice(n_palavras, vertices, palavra):\n",
        "  for i in range(n_palavras):\n",
        "    if(vertices[i][\"palavra\"] == palavra):\n",
        "      return vertices[i][\"indice\"]\n",
        "  return -1"
      ],
      "metadata": {
        "id": "gaBSORkH2Xth"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "NuGHaDAJ25c-"
      },
      "outputs": [],
      "source": [
        "def integraGrafo(memoria, n_palavras, vertices):\n",
        "  grafo = GrafoR(n_palavras)\n",
        "  for i in range(n_palavras):\n",
        "    busca = buscaVetorial(memoria, vertices[i][\"palavra\"])\n",
        "    proximos = []\n",
        "    for j in range(1,6):\n",
        "      palavra = busca[j]['chunk']\n",
        "      distancia = busca[j]['distance']\n",
        "      proximo = {\n",
        "          \"vizinho\": palavra,\n",
        "          \"indice\": buscaIndice(n_palavras, vertices, palavra),\n",
        "          \"distancia\": distancia\n",
        "      }\n",
        "      proximos.append(proximo)\n",
        "    vertices[i][\"proximos\"] = proximos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integraGrafo(m, d[0], d[1])\n",
        "print(d[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwrIDFFLvemn",
        "outputId": "72ffd224-ada1-49e9-e64d-224fc37965f4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'palavra': 'Ecossistema', 'indice': 0, 'proximos': [{'vizinho': 'Ecologia', 'indice': 15, 'distancia': 0.44486222}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.48550734}, {'vizinho': 'Bioma', 'indice': 20, 'distancia': 0.57568085}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.5811522}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.59003323}]}, {'palavra': 'Sustentabilidade', 'indice': 1, 'proximos': [{'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.44970125}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.5571618}, {'vizinho': 'Ambiental', 'indice': 45, 'distancia': 0.5643711}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.59003323}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.60961545}]}, {'palavra': 'Biodiversidade', 'indice': 2, 'proximos': [{'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.44970125}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.492421}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.49487936}, {'vizinho': 'Biodegradável', 'indice': 10, 'distancia': 0.5287854}, {'vizinho': 'Bioma', 'indice': 20, 'distancia': 0.5513243}]}, {'palavra': 'Reciclagem', 'indice': 3, 'proximos': [{'vizinho': 'Compostagem', 'indice': 9, 'distancia': 0.5640564}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.63607174}, {'vizinho': 'Recursos', 'indice': 13, 'distancia': 0.7419615}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.7432129}, {'vizinho': 'Bioma', 'indice': 20, 'distancia': 0.75601757}]}, {'palavra': 'Conservação', 'indice': 4, 'proximos': [{'vizinho': 'Preservação', 'indice': 14, 'distancia': 0.2443703}, {'vizinho': 'Proteção', 'indice': 44, 'distancia': 0.60836196}, {'vizinho': 'Aquicultura', 'indice': 34, 'distancia': 0.77395797}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.7833704}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.7846519}]}, {'palavra': 'Poluição', 'indice': 5, 'proximos': [{'vizinho': 'Desenvolvimento', 'indice': 22, 'distancia': 0.5565591}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.65016866}, {'vizinho': 'Aquicultura', 'indice': 34, 'distancia': 0.66577834}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.6681453}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.6769276}]}, {'palavra': 'Desmatamento', 'indice': 6, 'proximos': [{'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.50720704}, {'vizinho': 'Desenvolvimento', 'indice': 22, 'distancia': 0.53812826}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.6854651}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.71925545}, {'vizinho': 'Resíduos', 'indice': 39, 'distancia': 0.7342607}]}, {'palavra': 'Reflorestamento', 'indice': 7, 'proximos': [{'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.5673154}, {'vizinho': 'Desenvolvimento', 'indice': 22, 'distancia': 0.60254383}, {'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.607284}, {'vizinho': 'Reciclagem', 'indice': 3, 'distancia': 0.63607174}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.65016866}]}, {'palavra': 'Erosão', 'indice': 8, 'proximos': [{'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.62521744}, {'vizinho': 'Impacto', 'indice': 26, 'distancia': 0.7359667}, {'vizinho': 'Desmatamento', 'indice': 6, 'distancia': 0.75778896}, {'vizinho': 'Eólica', 'indice': 37, 'distancia': 0.76906836}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.78176826}]}, {'palavra': 'Compostagem', 'indice': 9, 'proximos': [{'vizinho': 'Reciclagem', 'indice': 3, 'distancia': 0.5640564}, {'vizinho': 'Biodegradável', 'indice': 10, 'distancia': 0.6273697}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.68495274}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.7193203}, {'vizinho': 'Efluentes', 'indice': 24, 'distancia': 0.7220284}]}, {'palavra': 'Biodegradável', 'indice': 10, 'proximos': [{'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.5287854}, {'vizinho': 'Biocombustível', 'indice': 35, 'distancia': 0.58690894}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.5973315}, {'vizinho': 'Compostagem', 'indice': 9, 'distancia': 0.6273697}, {'vizinho': 'Bioma', 'indice': 20, 'distancia': 0.64759797}]}, {'palavra': 'Emissões', 'indice': 11, 'proximos': [{'vizinho': 'Efluentes', 'indice': 24, 'distancia': 0.6606499}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.74496466}, {'vizinho': 'Resíduos', 'indice': 39, 'distancia': 0.74890196}, {'vizinho': 'Ambiental', 'indice': 45, 'distancia': 0.7719643}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.7770736}]}, {'palavra': 'Pegada', 'indice': 12, 'proximos': [{'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.77167964}, {'vizinho': 'Impacto', 'indice': 26, 'distancia': 0.81535625}, {'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.825389}, {'vizinho': 'Floresta', 'indice': 49, 'distancia': 0.8307852}, {'vizinho': 'Agricultura', 'indice': 33, 'distancia': 0.8317354}]}, {'palavra': 'Recursos', 'indice': 13, 'proximos': [{'vizinho': 'Resíduos', 'indice': 39, 'distancia': 0.70068}, {'vizinho': 'Reciclagem', 'indice': 3, 'distancia': 0.7419615}, {'vizinho': 'Ciclo', 'indice': 21, 'distancia': 0.7668636}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.7835539}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.78645265}]}, {'palavra': 'Preservação', 'indice': 14, 'proximos': [{'vizinho': 'Conservação', 'indice': 4, 'distancia': 0.2443703}, {'vizinho': 'Proteção', 'indice': 44, 'distancia': 0.5725999}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.76920426}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.78255415}, {'vizinho': 'Desenvolvimento', 'indice': 22, 'distancia': 0.80367845}]}, {'palavra': 'Ecologia', 'indice': 15, 'proximos': [{'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.44486222}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.52439535}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.55729043}, {'vizinho': 'Amazônia', 'indice': 28, 'distancia': 0.59514076}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.599265}]}, {'palavra': 'Habitat', 'indice': 16, 'proximos': [{'vizinho': 'Ambiental', 'indice': 45, 'distancia': 0.5995372}, {'vizinho': 'Fauna', 'indice': 17, 'distancia': 0.6318156}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.6592933}, {'vizinho': 'Flora', 'indice': 18, 'distancia': 0.67234945}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.6830626}]}, {'palavra': 'Fauna', 'indice': 17, 'proximos': [{'vizinho': 'Habitat', 'indice': 16, 'distancia': 0.6318156}, {'vizinho': 'Flora', 'indice': 18, 'distancia': 0.65714735}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.71442264}, {'vizinho': 'Ecologia', 'indice': 15, 'distancia': 0.71523505}, {'vizinho': 'Aquicultura', 'indice': 34, 'distancia': 0.7450721}]}, {'palavra': 'Flora', 'indice': 18, 'proximos': [{'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.63987845}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.6563211}, {'vizinho': 'Fauna', 'indice': 17, 'distancia': 0.65714735}, {'vizinho': 'Habitat', 'indice': 16, 'distancia': 0.67234945}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.68385947}]}, {'palavra': 'Agroecologia', 'indice': 19, 'proximos': [{'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.492421}, {'vizinho': 'Agrofloresta', 'indice': 32, 'distancia': 0.508341}, {'vizinho': 'Agricultura', 'indice': 33, 'distancia': 0.5148762}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.5795009}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.63834274}]}, {'palavra': 'Bioma', 'indice': 20, 'proximos': [{'vizinho': 'Biocombustível', 'indice': 35, 'distancia': 0.51633275}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.5513243}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.5575472}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.57568085}, {'vizinho': 'Biodegradável', 'indice': 10, 'distancia': 0.64759797}]}, {'palavra': 'Ciclo', 'indice': 21, 'proximos': [{'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.7561036}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.7562942}, {'vizinho': 'Recursos', 'indice': 13, 'distancia': 0.7668636}, {'vizinho': 'Eólica', 'indice': 37, 'distancia': 0.7754098}, {'vizinho': 'Impacto', 'indice': 26, 'distancia': 0.78002}]}, {'palavra': 'Desenvolvimento', 'indice': 22, 'proximos': [{'vizinho': 'Desmatamento', 'indice': 6, 'distancia': 0.53812826}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.5565591}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.60254383}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.6670773}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.73353815}]}, {'palavra': 'Economia', 'indice': 23, 'proximos': [{'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.48550734}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.5571618}, {'vizinho': 'Ecologia', 'indice': 15, 'distancia': 0.55729043}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.6534766}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.66104496}]}, {'palavra': 'Efluentes', 'indice': 24, 'proximos': [{'vizinho': 'Emissões', 'indice': 11, 'distancia': 0.6606499}, {'vizinho': 'Resíduos', 'indice': 39, 'distancia': 0.6702306}, {'vizinho': 'Eólica', 'indice': 37, 'distancia': 0.6844119}, {'vizinho': 'Compostagem', 'indice': 9, 'distancia': 0.7220284}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.72596467}]}, {'palavra': 'Gestão', 'indice': 25, 'proximos': [{'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.607284}, {'vizinho': 'Erosão', 'indice': 8, 'distancia': 0.62521744}, {'vizinho': 'Saneamento', 'indice': 40, 'distancia': 0.6883434}, {'vizinho': 'Uso', 'indice': 42, 'distancia': 0.69422066}, {'vizinho': 'Impacto', 'indice': 26, 'distancia': 0.7170292}]}, {'palavra': 'Impacto', 'indice': 26, 'proximos': [{'vizinho': 'Uso', 'indice': 42, 'distancia': 0.62858295}, {'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.7170292}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.7293782}, {'vizinho': 'Erosão', 'indice': 8, 'distancia': 0.7359667}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.7491785}]}, {'palavra': 'Mata', 'indice': 27, 'proximos': [{'vizinho': 'Zona', 'indice': 43, 'distancia': 0.7527229}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.79645383}, {'vizinho': 'Uso', 'indice': 42, 'distancia': 0.79911613}, {'vizinho': 'Água', 'indice': 48, 'distancia': 0.81159735}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.8193793}]}, {'palavra': 'Amazônia', 'indice': 28, 'proximos': [{'vizinho': 'Ecologia', 'indice': 15, 'distancia': 0.59514076}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.77977717}, {'vizinho': 'Flora', 'indice': 18, 'distancia': 0.7956481}, {'vizinho': 'Cerrado', 'indice': 29, 'distancia': 0.80585456}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.81873155}]}, {'palavra': 'Cerrado', 'indice': 29, 'proximos': [{'vizinho': 'Clima', 'indice': 46, 'distancia': 0.68559265}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.749758}, {'vizinho': 'Agricultura', 'indice': 33, 'distancia': 0.75019634}, {'vizinho': 'Flora', 'indice': 18, 'distancia': 0.7519864}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.7520429}]}, {'palavra': 'Pantanal', 'indice': 30, 'proximos': [{'vizinho': 'Cerrado', 'indice': 29, 'distancia': 0.78473806}, {'vizinho': 'Desenvolvimento', 'indice': 22, 'distancia': 0.82109773}, {'vizinho': 'Amazônia', 'indice': 28, 'distancia': 0.83526015}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.8420056}, {'vizinho': 'Fauna', 'indice': 17, 'distancia': 0.84834975}]}, {'palavra': 'Biotecnologia', 'indice': 31, 'proximos': [{'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.49487936}, {'vizinho': 'Ecologia', 'indice': 15, 'distancia': 0.52439535}, {'vizinho': 'Biocombustível', 'indice': 35, 'distancia': 0.5295755}, {'vizinho': 'Bioma', 'indice': 20, 'distancia': 0.5575472}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.5795009}]}, {'palavra': 'Agrofloresta', 'indice': 32, 'proximos': [{'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.508341}, {'vizinho': 'Agricultura', 'indice': 33, 'distancia': 0.58867675}, {'vizinho': 'Floresta', 'indice': 49, 'distancia': 0.7123889}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.71875}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.7247134}]}, {'palavra': 'Agricultura', 'indice': 33, 'proximos': [{'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.5148762}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.5846588}, {'vizinho': 'Agrofloresta', 'indice': 32, 'distancia': 0.58867675}, {'vizinho': 'Aquicultura', 'indice': 34, 'distancia': 0.62780905}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.66457677}]}, {'palavra': 'Aquicultura', 'indice': 34, 'proximos': [{'vizinho': 'Agricultura', 'indice': 33, 'distancia': 0.62780905}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.66577834}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.6947441}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.7013417}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.7103555}]}, {'palavra': 'Biocombustível', 'indice': 35, 'proximos': [{'vizinho': 'Bioma', 'indice': 20, 'distancia': 0.51633275}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.5295755}, {'vizinho': 'Biodegradável', 'indice': 10, 'distancia': 0.58690894}, {'vizinho': 'Biodiversidade', 'indice': 2, 'distancia': 0.58953094}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.7101712}]}, {'palavra': 'Solar', 'indice': 36, 'proximos': [{'vizinho': 'Ambiental', 'indice': 45, 'distancia': 0.6991949}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.72045124}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.7705814}, {'vizinho': 'Clima', 'indice': 46, 'distancia': 0.7739404}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.77604973}]}, {'palavra': 'Eólica', 'indice': 37, 'proximos': [{'vizinho': 'Efluentes', 'indice': 24, 'distancia': 0.6844119}, {'vizinho': 'Erosão', 'indice': 8, 'distancia': 0.76906836}, {'vizinho': 'Ciclo', 'indice': 21, 'distancia': 0.7754098}, {'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.7884386}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.7898941}]}, {'palavra': 'Hidrelétrica', 'indice': 38, 'proximos': [{'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.7500137}, {'vizinho': 'Floresta', 'indice': 49, 'distancia': 0.77733886}, {'vizinho': 'Ambiental', 'indice': 45, 'distancia': 0.81261295}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.822649}, {'vizinho': 'Amazônia', 'indice': 28, 'distancia': 0.8388749}]}, {'palavra': 'Resíduos', 'indice': 39, 'proximos': [{'vizinho': 'Efluentes', 'indice': 24, 'distancia': 0.6702306}, {'vizinho': 'Recursos', 'indice': 13, 'distancia': 0.70068}, {'vizinho': 'Desmatamento', 'indice': 6, 'distancia': 0.7342607}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.74025464}, {'vizinho': 'Emissões', 'indice': 11, 'distancia': 0.74890196}]}, {'palavra': 'Saneamento', 'indice': 40, 'proximos': [{'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.66770077}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.68094075}, {'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.6883434}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.692592}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.70935684}]}, {'palavra': 'Tratamento', 'indice': 41, 'proximos': [{'vizinho': 'Desmatamento', 'indice': 6, 'distancia': 0.50720704}, {'vizinho': 'Reflorestamento', 'indice': 7, 'distancia': 0.5673154}, {'vizinho': 'Desenvolvimento', 'indice': 22, 'distancia': 0.6670773}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.6681453}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.6945189}]}, {'palavra': 'Uso', 'indice': 42, 'proximos': [{'vizinho': 'Impacto', 'indice': 26, 'distancia': 0.62858295}, {'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.69422066}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.74628335}, {'vizinho': 'Ciclo', 'indice': 21, 'distancia': 0.78336835}, {'vizinho': 'Mata', 'indice': 27, 'distancia': 0.79911613}]}, {'palavra': 'Zona', 'indice': 43, 'proximos': [{'vizinho': 'Água', 'indice': 48, 'distancia': 0.6351434}, {'vizinho': 'Aquicultura', 'indice': 34, 'distancia': 0.7335907}, {'vizinho': 'Mata', 'indice': 27, 'distancia': 0.7527229}, {'vizinho': 'Clima', 'indice': 46, 'distancia': 0.77785724}, {'vizinho': 'Desenvolvimento', 'indice': 22, 'distancia': 0.81333435}]}, {'palavra': 'Proteção', 'indice': 44, 'proximos': [{'vizinho': 'Preservação', 'indice': 14, 'distancia': 0.5725999}, {'vizinho': 'Biotecnologia', 'indice': 31, 'distancia': 0.60122514}, {'vizinho': 'Conservação', 'indice': 4, 'distancia': 0.60836196}, {'vizinho': 'Poluição', 'indice': 5, 'distancia': 0.6962425}, {'vizinho': 'Gestão', 'indice': 25, 'distancia': 0.75378656}]}, {'palavra': 'Ambiental', 'indice': 45, 'proximos': [{'vizinho': 'Sustentabilidade', 'indice': 1, 'distancia': 0.5643711}, {'vizinho': 'Habitat', 'indice': 16, 'distancia': 0.5995372}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.6495086}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.6821217}, {'vizinho': 'Ecologia', 'indice': 15, 'distancia': 0.6851665}]}, {'palavra': 'Clima', 'indice': 46, 'proximos': [{'vizinho': 'Cerrado', 'indice': 29, 'distancia': 0.68559265}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.7103961}, {'vizinho': 'Economia', 'indice': 23, 'distancia': 0.74963707}, {'vizinho': 'Resíduos', 'indice': 39, 'distancia': 0.75217044}, {'vizinho': 'Bioma', 'indice': 20, 'distancia': 0.758798}]}, {'palavra': 'Solo', 'indice': 47, 'proximos': [{'vizinho': 'Habitat', 'indice': 16, 'distancia': 0.78735816}, {'vizinho': 'Recursos', 'indice': 13, 'distancia': 0.85113084}, {'vizinho': 'Ciclo', 'indice': 21, 'distancia': 0.85947514}, {'vizinho': 'Clima', 'indice': 46, 'distancia': 0.8794722}, {'vizinho': 'Ambiental', 'indice': 45, 'distancia': 0.8908264}]}, {'palavra': 'Água', 'indice': 48, 'proximos': [{'vizinho': 'Zona', 'indice': 43, 'distancia': 0.6351434}, {'vizinho': 'Agricultura', 'indice': 33, 'distancia': 0.7335344}, {'vizinho': 'Aquicultura', 'indice': 34, 'distancia': 0.734061}, {'vizinho': 'Agroecologia', 'indice': 19, 'distancia': 0.77640337}, {'vizinho': 'Habitat', 'indice': 16, 'distancia': 0.7900934}]}, {'palavra': 'Floresta', 'indice': 49, 'proximos': [{'vizinho': 'Agrofloresta', 'indice': 32, 'distancia': 0.7123889}, {'vizinho': 'Ambiental', 'indice': 45, 'distancia': 0.73255575}, {'vizinho': 'Tratamento', 'indice': 41, 'distancia': 0.7515701}, {'vizinho': 'Flora', 'indice': 18, 'distancia': 0.7598229}, {'vizinho': 'Ecossistema', 'indice': 0, 'distancia': 0.775733}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsUUPVLa2JAs"
      },
      "source": [
        "## 2. Gravar dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "S8aX3NJd2JAs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcUaBUFE2JAs"
      },
      "source": [
        "## 3. Inserir vértice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rEUyOKTo2JAt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8PvH4ed2JAt"
      },
      "source": [
        "## 4. Inserir aresta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6u2WV2hb2JAt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMVke0Al2JAt"
      },
      "source": [
        "## 5. Remover vértice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CqO6N1PP2JAu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvUaJjZS2JAu"
      },
      "source": [
        "## 6. Remover aresta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hmD-cjiW2JAu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8SKdKg2JAv"
      },
      "source": [
        "## 7. Mostrar conteúdo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tlbI-jgd2JA1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS8x6Fjd2JA2"
      },
      "source": [
        "## 8. Mostrar grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "J6uG3Bl12JA2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs6GqASM2JA2"
      },
      "source": [
        "## 9. Apresentar conexidade do grafo e o reduzido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sUTjaER52JA2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YNbDvEe2JA3"
      },
      "source": [
        "# Menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AdLQfMUkWbyX",
        "outputId": "5071352b-f96f-4275-bba9-2c6d194d94c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiliazing embeddings:  normal\n",
            "OK.\n",
            "\n",
            "Menu:\n",
            "    1) Ler dados do arquivo em python\n",
            "    2) Gravar dados no arquivo grafo.txt\n",
            "    3) Inserir vértice\n",
            "    4) Inserir aresta\n",
            "    5) Remove vértice\n",
            "    6) Remove aresta\n",
            "    7) Mostrar conteúdo do arquivo\n",
            "    8) Mostrar grafo\n",
            "    9) Apresentar a conexidade do grafo e o reduzido\n",
            "    10) Encerrar a aplicação\n",
            "\n",
            "1\n",
            "Grafo lido com sucesso!\n",
            "\n",
            "Menu:\n",
            "    1) Ler dados do arquivo em python\n",
            "    2) Gravar dados no arquivo grafo.txt\n",
            "    3) Inserir vértice\n",
            "    4) Inserir aresta\n",
            "    5) Remove vértice\n",
            "    6) Remove aresta\n",
            "    7) Mostrar conteúdo do arquivo\n",
            "    8) Mostrar grafo\n",
            "    9) Apresentar a conexidade do grafo e o reduzido\n",
            "    10) Encerrar a aplicação\n",
            "\n",
            "10\n",
            "Encerrando programa...\n"
          ]
        }
      ],
      "source": [
        "memoria = Memory(chunking_strategy={\"mode\": \"sliding_window\", \"window_size\": 1, \"overlap\": 0})\n",
        "fim = False\n",
        "\n",
        "while(fim == False):\n",
        "    print(\n",
        "'''\n",
        "Menu:\n",
        "    1) Ler dados do arquivo em python\n",
        "    2) Gravar dados no arquivo grafo.txt\n",
        "    3) Inserir vértice\n",
        "    4) Inserir aresta\n",
        "    5) Remove vértice\n",
        "    6) Remove aresta\n",
        "    7) Mostrar conteúdo do arquivo\n",
        "    8) Mostrar grafo\n",
        "    9) Apresentar a conexidade do grafo e o reduzido\n",
        "    10) Encerrar a aplicação\n",
        "''')\n",
        "    choice = int(input())\n",
        "    if choice == 1: # Lê grafo\n",
        "        dados = leArquivoHTTP()\n",
        "        #dados = leArquivo(\"palavras.txt\")\n",
        "        embedding(memoria, dados[\"palavras\"], dados[\"n_palavras\"])\n",
        "        print(\"Grafo lido com sucesso!\")\n",
        "\n",
        "    elif choice == 2: # Grava dados no arquivo .txt\n",
        "        print(\"Dados salvos com sucesso!\")\n",
        "\n",
        "    elif choice == 3: # Insere vértice\n",
        "        print(\"Vértice inserido com sucesso!\")\n",
        "\n",
        "    elif choice == 4: # Insere aresta\n",
        "        print(\"Arestas inseridas com sucesso!\")\n",
        "\n",
        "    elif choice == 5: # Remove vértice\n",
        "        print(\"Vértice removido com sucesso!\")\n",
        "\n",
        "    elif choice == 6: # Remove varesta\n",
        "        print(\"Aresta removida com sucesso!\")\n",
        "\n",
        "    elif choice == 7: # Imprime arquivo\n",
        "        print(\"oi\")\n",
        "\n",
        "    elif choice == 8: # Exibe grafo\n",
        "        print(\"oi\")\n",
        "\n",
        "    elif choice == 9: # Apresenta a conexidade do grafo e grafo reduzido\n",
        "        print(\"oi\")\n",
        "\n",
        "    elif choice == 10: # Encerra\n",
        "        fim = True\n",
        "        print(\"Encerrando programa...\")\n",
        "\n",
        "    else:\n",
        "        print(\"Opção inválida.\")\n",
        "\n",
        "    time.sleep(4) # Volta para o menu após 4 segundos\n",
        "\n",
        "    if os.name == 'nt': # Limpa o terminal\n",
        "        os.system('cls') # Caso o OS seja Windows\n",
        "    else:\n",
        "        os.system('clear') # Caso o OS seja Linux ou MacOS"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nL7lcvob_Vsv",
        "f4Fd36vBfY_m",
        "jUL4VcKo2JAl",
        "g2sI3d7Qz7ck",
        "Nt727Vzj0Kos",
        "XMuxrf07kEw_",
        "rsUUPVLa2JAs",
        "rcUaBUFE2JAs",
        "-8PvH4ed2JAt",
        "nMVke0Al2JAt",
        "cvUaJjZS2JAu",
        "4f8SKdKg2JAv",
        "kS8x6Fjd2JA2",
        "hs6GqASM2JA2"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}